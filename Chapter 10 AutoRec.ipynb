{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoRec\n",
    "\n",
    "从 AutoRec 开始，要进入使用深度学习技术进行 ctr 预估的部分了。第一个模型是 AutoRec，其使用协同过滤的用户和物品的共现矩阵，完成物品或者用户的自编码。再利用自编码，得到用户对物品的预估评分，最后利用评分进行推荐和排序。简述其过程就是，几个数据 $x$ 输入到模型之后，得到一个输出 $\\hat{x}$，模型训练时候的目标是使得 $x$ 和 $\\hat{x}$ 的值尽可能的接近。用公式表达就是：$min_{\\theta}\\sum_{i=1}^n||x^{(i)} - h(x^{(i)}; \\theta)||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# working directory\n",
    "BASEDIR = os.getcwd()\n",
    "dataframe = pd.read_csv(BASEDIR + '/assets/datasets/ml-latest-small/ratings.csv')\n",
    "\n",
    "userId_dict = {}\n",
    "movieId_dict = {}\n",
    "\n",
    "userId_unique = dataframe.userId.unique()\n",
    "movieId_unique = dataframe.movieId.unique()\n",
    "\n",
    "idx = 0\n",
    "for n in range(userId_unique.shape[0]):\n",
    "    userId_dict[userId_unique[idx]] = idx\n",
    "    idx += 1\n",
    "\n",
    "idx = 0\n",
    "for n in range(movieId_unique.shape[0]):\n",
    "    movieId_dict[movieId_unique[idx]] = idx\n",
    "    idx += 1\n",
    "\n",
    "i = []\n",
    "v = []\n",
    "\n",
    "for row in dataframe.itertuples():\n",
    "    i.append([userId_dict[row.userId], movieId_dict[row.movieId]])\n",
    "    v.append(float(row.rating))\n",
    "\n",
    "i = torch.LongTensor(i)\n",
    "v = torch.DoubleTensor(v)\n",
    "X_train = torch.sparse.DoubleTensor(i.t(), v).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "EPOCH: 0, loss: 0.566581\nEPOCH: 10, loss: 1.809191\nEPOCH: 20, loss: 0.631760\nEPOCH: 30, loss: 1.134131\nEPOCH: 40, loss: 1.035285\nEPOCH: 50, loss: 1.330597\nEPOCH: 60, loss: 1.542136\nEPOCH: 70, loss: 1.292075\nEPOCH: 80, loss: 1.650838\nEPOCH: 90, loss: 1.480408\n"
    }
   ],
   "source": [
    "# PyTorch Version\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.double\n",
    "\n",
    "INPUT_DIMENSION = X_train.shape[0]\n",
    "\n",
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.h1 = nn.Linear(INPUT_DIMENSION, m).double()\n",
    "        self.h2 = nn.Linear(m, INPUT_DIMENSION).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.h1(x)\n",
    "        return self.h2(x).double()\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCH = 100\n",
    "PRINT_STEP = EPOCH / 10\n",
    "\n",
    "m = 10\n",
    "autoRec = AutoRec(10)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoRec.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    optimizer.zero_grad()\n",
    "    index = np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)\n",
    "    X_batch = X_train[:, index].T\n",
    "\n",
    "    y_hat = autoRec(X_batch.double())\n",
    "    loss = loss_fn(y_hat, X_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % PRINT_STEP == 0:\n",
    "        print('EPOCH: %d, loss: %f' % (epoch, loss))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bitmlfmcondafca915a6e1ae4fb7ab8b19f2bd50bf32",
   "display_name": "Python 3.6.8 64-bit ('mlfm': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}