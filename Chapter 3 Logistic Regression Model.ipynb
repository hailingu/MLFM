{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bit2efa5cda313c4cc1b870adcb9a2899de",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "和前面提到的 Linear Regression 一样， Logistic Regression 也属于 Generalized Linear Model。Logistic Regression 是 Linear Regression 很直接的扩展，Logistic Regression 把 Linear Regression 的结果送入到 sigmoid 函数中，计算得到结果。\n",
    "\n",
    "## sigmoid 函数\n",
    "\n",
    "$\\begin{align*}\n",
    "sigmoid(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{e^x + 1}\n",
    "\\end{align*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "x = np.linspace(-10,10,200)\n",
    "y = 1 / (1 + np.exp(-1 * x))\n",
    "plt.plot(x, y, 'b', label='sigmoid(x) = e^x / (e^x + 1)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('sigmoid(x)')\n",
    "plt.title('sigmoid(x) = e^x / (e^x + 1)')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很多人常讲，Logistic Regression 最后得到的结果是一个概率值。这个值真的是概率值么？指数分布簇可以给我们答案。\n",
    "\n",
    "## Exponential Family\n",
    "\n",
    "单一变量的 exponential family 是 $f(x|\\theta)=h(x)e^{\\eta(\\theta)T(x)-A(\\theta)}$\n",
    "\n",
    "其中 $\\eta(\\theta)$ 是自然参数，在 Bernoulli 分布中，只有一个自然参数，那就是 $p$。另外的，$A(\\theta)$ 可以表示成 $A(\\theta) = f(\\eta(\\theta))$ 的形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 $x \\sim Bernoulli(x|p) = p^x(1-p)^{1-x}$，那么就有：\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "Bernoulli(x|p) & = p^x(1-p)^{1-x} \\\\\n",
    "& = e^{log(p^x(1-p)^{1-x})} \\\\\n",
    "& = e^{xlog(p) + (1-x)log(1-p)} \\\\ \n",
    "& = e^{xlog(\\frac{p}{1-p}) + log(1-p)}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "对应指数分布簇，即有 $h(x)=1$，$\\eta(\\theta)=log(\\frac{p}{1-p})$，$T(x)=x$，$A(\\theta)=-log(1-p)$。稍微对 p 做一些分析：\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\eta(\\theta) & = log(\\frac{p}{1-p}) \\\\\n",
    "\\Rightarrow e^{\\eta(\\theta)} \\cdot (1-p) & = p \\\\\n",
    "e^{\\eta(\\theta)} & = p(1 + e^{\\eta(\\theta)}) \\\\\n",
    "\\frac{e^{\\eta(\\theta)}}{1+e^{\\eta(\\theta)}} & = p \n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，如果使用 $\\eta(\\theta)) = \\mathbf{\\theta}^T \\mathbf{x}$，那么 $p = \\frac{1}{1+e^{-\\theta^T x}}$，所以有人会说 Logistic Regression 的输出是一个概率值。在传统的 Statistical Machine Learning 中，通过预先选择一个模型，然后根据数据，学习出模型的参数值。过去的一段时间内，我一度认为 Logistic Regression 的输出值，不能代表概率值，其实是部分正确的，如果说 $\\eta(\\theta)=\\mathbf{\\theta}^T \\mathbf{x}$ 能真实的反映 $\\eta(\\theta)$ 函数，那么 $p$ 的值就是概率值；否则就不行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似于 Linear Regression，要通过训练数据获取 $\\theta$ 的值，也需要累死的两步，设置 Loss 和使用 Learning Method。在 Logistic Regression 中，常用的损失函数称为 logloss 或者 cross-entropy，两者分别是 Statistics 和 Information Theory 视角的表述。\n",
    "\n",
    "## Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ]
}