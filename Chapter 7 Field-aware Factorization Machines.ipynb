{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field-aware Factorization Machines\n",
    "\n",
    "在 Factorization Machines 的基础之上，做了些许修改。在 Factorization Machines 中，每一个特征 $f$ 对应唯一的向量 $f_i$，特征交叉的时候就是直接与另一个特征对应的向量 $f_j$ 点乘后作为交叉特征的系数。但是在 Field-aware Factorization Machines 中，对这种特征交叉做了一些修改，把特征划分到不同的 Field 上（假如有 n 个特征，然后把它们划分到了 $f$ 个域上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import os\n",
    "\n",
    "BASEDIR = os.getcwd()\n",
    "\n",
    "features = []\n",
    "fields = []\n",
    "values = []\n",
    "y_train = []\n",
    "field_cnt = -1\n",
    "feature_cnt = -1\n",
    "with open(BASEDIR + '/assets/datasets/criteo_ctr/small_train.txt') as f:\n",
    "    line = f.readline()\n",
    "    line = line.strip('\\n')\n",
    "    while line:\n",
    "        elems = line.split(' ')\n",
    "        y_train.append(int(elems[0]))\n",
    "        tmp_feature_idx = []\n",
    "        tmp_field_idx = []\n",
    "        tmp_feature_value = []\n",
    "        for i in range(1, len(elems)):\n",
    "            field, feature, value = elems[i].split(':')\n",
    "            field_cnt = max(field_cnt, int(field))\n",
    "            feature_cnt = max(feature_cnt, int(feature))\n",
    "            tmp_feature_idx.append([0, int(feature)])\n",
    "            tmp_field_idx.append(int(field))\n",
    "            tmp_feature_value.append(float(value))\n",
    "        features.append(tmp_feature_idx)\n",
    "        fields.append(tmp_field_idx)\n",
    "        values.append(tmp_feature_value)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b73dd265865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_part\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlfm/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlfm/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PyTorch Version\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.float\n",
    "\n",
    "X_train = []\n",
    "for feature, field, value in zip(features, fields, values):\n",
    "    feature.append([0, feature_cnt])\n",
    "    value.append(0.0)\n",
    "    X_train.append({'feature': feature, 'value': value, 'field': field})\n",
    "\n",
    "INPUT_DIMENSION, OUTPUT_DIMENSION = feature_cnt + 1, 1\n",
    "w = torch.randn(INPUT_DIMENSION, OUTPUT_DIMENSION, device=device, dtype=dtype, requires_grad=True)\n",
    "k = 6\n",
    "cv = torch.randn(feature_cnt + 1, field_cnt + 1, k, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "EPOCH = 3\n",
    "PRINT_STEP = EPOCH / 10\n",
    "N = len(y_train)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i in range(N):\n",
    "        x = X_train[i]\n",
    "        y = y_train[i]\n",
    "\n",
    "        # linear part\n",
    "        i = torch.LongTensor(x['feature'])\n",
    "        v = torch.FloatTensor(x['value'])\n",
    "\n",
    "        dense = torch.sparse.FloatTensor(i.t(), v).to_dense()\n",
    "        linear_part = w.T.mm(dense.T)\n",
    "\n",
    "        cross_part = 0\n",
    "        for f1 in range(0, len(x['field']) - 1):\n",
    "            for f2 in range(f1 + 1, len(x['field'])):\n",
    "                f1_feature = x['feature'][f1][1]\n",
    "                f2_feature = x['feature'][f2][1]\n",
    "\n",
    "                f1_field = x['field'][f1]\n",
    "                f2_field = x['field'][f2]\n",
    "\n",
    "                factor = cv[f1_feature][f1_field].mul(cv[f2_feature][f2_field]).sum()\n",
    "                cross_part += factor * x['value'][f1] * x['value'][f2]\n",
    "\n",
    "        y_hat = linear_part + cross_part\n",
    "        loss = (y_hat - y)**2 / 2\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w -= LEARNING_RATE * w.grad\n",
    "            cv -= LEARNING_RATE * cv.grad\n",
    "\n",
    "            # Manually zero the gradients after updating weights\n",
    "            w.grad.zero_()\n",
    "            cv.grad.zero_()\n",
    "\n",
    "    if epoch % PRINT_STEP == 0:\n",
    "        print('EPOCH: %d, loss: %f' % (epoch, loss))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bitmlfmcondafca915a6e1ae4fb7ab8b19f2bd50bf32",
   "language": "python",
   "display_name": "Python 3.6.8 64-bit ('mlfm': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}