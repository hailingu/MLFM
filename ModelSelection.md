# Model Selection

> 在现实任务中，我们往往有多种学习算法可供选择，甚至对同一个学习算法，当使用不同的参数配置时，可会产生不同模型，那么，我们该选用哪一个学习算法，使用哪一种参数配置呢？这就是机器学习中的“模型选择”（model selection）问题。
——周志华 机器学习

模型的预测输出与样本的真实输出之间的差异称为“误差”，模型在训练集上的误差称为“训练误差”或“经验误差”，在新样本上的误差称为“泛化误差”，我们最终的目的是希望训练出一个泛化误差小的模型出来，理想的解决方案是获取候选模型的泛化误差，然后选择泛化误差最小的模型，然而由于我们事先并不知道新样本是什么样的，无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，因此通常使用模型在测试集上的测试误差作为泛化误差的近似，测试集尽量与训练集互斥，否则可能得到一个偏“乐观”的估计

假设容量为n 的全部样本集：$$ D=\{(x_1,y_1),(x_2,y_2),\ldots,(x_n,y_n)\}$$ 划分为互斥的两个集合 $$Train =\{(x_1,y_1),(x_2,y_2),\ldots,(x_m,y_m)\}$$ ，容量为 $$m$$，和 $$Test=\{(x_1,y_1),(x_2,y_2),\ldots,(x_t,y_t)\}$$ ，容量为 $$t$$，$$Train$$ 用于模型的训练评估、选择、调参，$$Test$$ 用于测试模型实际的泛化能力（精度、召回率等）。还有一种方式把原始数据集划分成 3 个集合，$$Train$$、$$Dev$$、$$Test$$，其中 $$Train$$ 用来训练模型， $$Dev$$ 用来调整参数， $$Test$$ 用来验证模型的效果。

划分要尽可能保持数据分布的一致性，例如在分类任务中，至少要保持样本的类别比例相近，单次划分得到的结果往往不太可靠，可多次随机划分，重复试验，取测试误差的平均值作为泛化误差的估计。在小规模的数据集上一般使用 (0.6,0.4) 的比例划分，如果数据训练集很大，超过 100 万，可以考虑使用 (0.98,0.02) 这样的比例划分。
